{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7HVC_dMouSY"
   },
   "source": [
    "# CIFAR-10 Example with Custom CNN\n",
    "\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. For this exercise, the dataset is subset to 5000 training and 1000 validation.\n",
    "\n",
    "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.\n",
    "\n",
    "Here are the classes in the dataset, as well as 10 random images from each: \n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1tsF12lE9IIW8BVFZgeEgMQIBG_nvWCXY' alt=\"CFIAR-10\" width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y-fl5rp718m9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "import ssl # maybe necessary to avoid ssl certificate error\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ba3Q64o15sl"
   },
   "source": [
    "## Load the internal data from `torchvision.datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x6x048No14IC",
    "outputId": "524c366f-5ea1-4302-d770-d31dafa8273e"
   },
   "outputs": [],
   "source": [
    "train_data = datasets.CIFAR10(root = '.data', train = True, download=True, transform = transforms.ToTensor())\n",
    "test_data  = datasets.CIFAR10(root = '.data', train = False, download=True, transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_data.class_to_idx\n",
    "print(class_names)\n",
    "class_idx_to_names = dict([(j,i) for i,j in class_names.items()])\n",
    "print(class_idx_to_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset to 5000 training and 1000 testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(500)\n",
    "train_idx = np.random.choice(len(train_data), round(len(train_data)*0.1), replace=False)\n",
    "test_idx = np.random.choice(len(test_data), round(len(test_data)*0.1), replace=False)\n",
    "\n",
    "train_data = Subset(train_data, train_idx)\n",
    "test_data = Subset(test_data, test_idx)\n",
    "\n",
    "print(train_data)\n",
    "print(len(train_data))\n",
    "\n",
    "print(test_data)\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 594
    },
    "id": "Etr1WSqnLvFV",
    "outputId": "cbb1fb8f-f095-4c5e-ea4e-132d00000d3d"
   },
   "outputs": [],
   "source": [
    "def img_plotter(img_list, lab_list):\n",
    "    ncols = 4\n",
    "    nrows = int(np.ceil(len(img_list)/ncols))\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*2.5,nrows*2.5))\n",
    "    for i in range(len(img_list)):\n",
    "        image = img_list[i]\n",
    "        label = lab_list[i]\n",
    "        ax = axes.flat[i]\n",
    "        if len(image.shape) == 3:\n",
    "            ax.imshow(np.transpose(image.numpy(), (1, 2, 0)))\n",
    "        else:\n",
    "            ax.imshow(image.numpy())\n",
    "        ax.set_title(label)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "# View the first few images\n",
    "count = 0\n",
    "img_list = []\n",
    "lab_list = []\n",
    "for image, label in train_data:\n",
    "    img_list.append(image)\n",
    "    lab_list.append(class_idx_to_names[label])\n",
    "    count += 1\n",
    "    if count >= 16:\n",
    "        break\n",
    "\n",
    "img_plotter(img_list, lab_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5aeP6_TLXeM"
   },
   "source": [
    "## Pre-process the data\n",
    "\n",
    "Since the images already have standardized sizes, this step will only do normalization and random changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G7sY16YpLRjp",
    "outputId": "026048b1-91da-4332-933d-331e8da38900"
   },
   "outputs": [],
   "source": [
    "# Find the mean and standard deviation of the training data\n",
    "image_mean = []\n",
    "image_szs  = []\n",
    "\n",
    "for image, label in DataLoader(train_data, batch_size=1, shuffle=False):\n",
    "    image_mean.append(image.mean(dim=[0,2,3])) # the first dimension is batch size\n",
    "    image_szs .append(tuple(image.size()[2:]))\n",
    "\n",
    "means = torch.stack(image_mean).mean(dim = 0)\n",
    "stds  = torch.stack(image_mean).std (dim = 0)\n",
    "\n",
    "print(f'Mean values of each channel: {means}')\n",
    "print(f'Mean values of each channel: {stds }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TkD9QHWNoIcG",
    "outputId": "4b43ffac-8f08-4912-d5d4-3d1a445c5b5e"
   },
   "outputs": [],
   "source": [
    "# Re-load the data with transformations\n",
    "# - transforms.RandomRotation: randomly rotate within (min,max) or +/-degrees range\n",
    "# - transforms.RandomHorizontalFlip: randomly horizontal flip with given probability\n",
    "# - transforms.RandomCrop: crop the image to given size, and optionally pad the edge of the image\n",
    "train_transforms = transforms.Compose([\n",
    "                           transforms.RandomRotation(5),\n",
    "                           transforms.RandomHorizontalFlip(0.5),\n",
    "                           transforms.RandomCrop(32, padding=2),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=means,\n",
    "                                                std=stds)\n",
    "                       ])\n",
    "test_transforms = transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=means,\n",
    "                                                std=stds)\n",
    "                       ])\n",
    "\n",
    "\n",
    "torch.manual_seed(999)\n",
    "\n",
    "train_data = datasets.CIFAR10('./data', train=True, download=True,\n",
    "                              transform=train_transforms)\n",
    "test_data = datasets.CIFAR10('./data', train=False, download=True,\n",
    "                             transform=test_transforms)\n",
    "\n",
    "# subset again\n",
    "train_data = Subset(train_data, train_idx)\n",
    "test_data = Subset(test_data, test_idx)\n",
    "\n",
    "batch_size = 10\n",
    "train_iterator = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_iterator = DataLoader(test_data, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-N-cjriurSQ",
    "outputId": "890c98ab-d2f8-454d-bd69-227e58b01e93"
   },
   "outputs": [],
   "source": [
    "for i,(img_list, lab_list) in enumerate(train_iterator):\n",
    "  break\n",
    "\n",
    "print(img_list.shape, img_list.dtype)\n",
    "print(lab_list.shape, img_list.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 888
    },
    "id": "KIIrzwDtsYZz",
    "outputId": "14195c7d-2ef5-48d4-feaa-6cb324277280"
   },
   "outputs": [],
   "source": [
    "# RView the first few images after transformation\n",
    "# Note the warnings occur because the normalization causes the values of image \n",
    "#   pixels to be out of the range of [0,1]. matplotlib expects the values of \n",
    "#   every pixel to be between [0,1], and clips out of range values. \n",
    "count = 0\n",
    "img_list = []\n",
    "lab_list = []\n",
    "for image, label in train_data:\n",
    "    img_list.append(image)\n",
    "    lab_list.append(class_idx_to_names[label])\n",
    "    count += 1\n",
    "    if count >= 16:\n",
    "        break\n",
    "\n",
    "img_plotter(img_list, lab_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VB8CMq8U2B-8"
   },
   "source": [
    "## Please Fill Out This Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rbPUf8-Qxivv"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        pass\n",
    "\n",
    "    def forward(self, X):\n",
    "        pass\n",
    "\n",
    "output_size = ? # please fill this too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Okp3FwNCQqSp"
   },
   "source": [
    "## Instantiate the model, define loss and optimization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nceG4kfb2Kzd",
    "outputId": "16d0faca-e6f9-4458-e803-f62c0f801b63"
   },
   "outputs": [],
   "source": [
    "model = CNN(output_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 100\n",
    "\n",
    "def count_parameters(model):\n",
    "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    for item in params:\n",
    "        print(f'{item:>6}')\n",
    "    print(f'______\\n{sum(params):>6}')\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sy4Jjy7W2TD-"
   },
   "source": [
    "## Train the Model\n",
    "\n",
    "In deep neural networks, initialization matters to model performance. Initializing all the parameters to zero (or other constant numbers) will make the neurons all learn the same features during training. Also, when the parameters are too small or too large, the model will have vanishing or exploding gradients. Therefore, the common practice is to initialize the model parameters to small random numbers, in inverse proportion to the number of parameters.\n",
    "\n",
    "Common formal methods: Xavier initialization, Kaiming initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BcvfsJFu2Sbm",
    "outputId": "809ec923-6762-445d-e0cb-2cc02647f606"
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight.data, nonlinearity='relu')\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight.data, gain=nn.init.calculate_gain('relu'))\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "model.apply(initialize_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uH5xbbOy21-R"
   },
   "outputs": [],
   "source": [
    "def train_model(num_epochs, model, train_iterator, optimizer, criterion, device):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_epochs = num_epochs\n",
    "    train_losses = []\n",
    "\n",
    "    model.to(device) # attach model to device\n",
    "    criterion.to(device) # attach loss function to device\n",
    "\n",
    "    for i in range(train_epochs):\n",
    "        for j, (img_list, lab_list) in enumerate(train_iterator):\n",
    "\n",
    "            img_list = img_list.to(device) # attach training data to device\n",
    "            lab_list = lab_list.to(device) # attach training data to device\n",
    "\n",
    "            lab_pred = model(img_list)\n",
    "            loss = criterion(lab_pred, lab_list)\n",
    "\n",
    "            if j%200 == 0:\n",
    "                print(f'epoch: {i:2}  batch: {j:4} [{batch_size*j:6}/50000]  loss: {loss.item():10.8f}')\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_losses.append(loss)\n",
    "\n",
    "    print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed\n",
    "\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FdO7l9t-2iFP",
    "outputId": "782f6baf-d04d-41b4-cd26-992109fc07d6"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_losses = train_model(num_epochs, model, train_iterator, optimizer, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgNQbXa91Qes"
   },
   "source": [
    "Plot loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "vobwwkh52wYA",
    "outputId": "be3475f5-48fe-47d8-f0e1-78d23bbeb9ae"
   },
   "outputs": [],
   "source": [
    "if num_epochs == len(train_losses):\n",
    "    plt.plot(torch.Tensor(train_losses).detach().numpy())\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('CE Loss')\n",
    "else:\n",
    "    raise 'Training is not finished.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YA2qnfneivuD"
   },
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'CNN_CIFAR-10.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtVKHjEcilhW"
   },
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yH0BX_T023nu",
    "outputId": "39c0f575-4c30-4464-8edd-8befba139173"
   },
   "outputs": [],
   "source": [
    "model2 = CNN(10)\n",
    "model2.load_state_dict(torch.load('CNN_CIFAR-10.pt'))\n",
    "\n",
    "def calc_accuracy(y_pred, y):\n",
    "    which = y_pred.argmax(1)\n",
    "    correct = (which == y).float().mean() * 100\n",
    "    return correct\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "test_losses = []\n",
    "test_accuracy = []\n",
    "\n",
    "model2.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for j, (img_list, lab_list) in enumerate(test_iterator):\n",
    "        lab_pred = model2(img_list)\n",
    "\n",
    "        loss = criterion(lab_pred, lab_list)\n",
    "        test_losses.append(loss)\n",
    "\n",
    "        acc = calc_accuracy(lab_pred, lab_list)\n",
    "        test_accuracy.append(acc)\n",
    "\n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "DUEFGCRS6pOC",
    "outputId": "6f5bc5f1-5fa4-46d0-ba02-bd888633c3f9"
   },
   "outputs": [],
   "source": [
    "plt.plot(torch.Tensor(test_losses).detach().numpy())\n",
    "plt.xlabel('Test iterations')\n",
    "plt.ylabel('CE Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "g9VNH0ep69N8",
    "outputId": "29e1808b-e144-4383-ce62-0fd59bbc151d"
   },
   "outputs": [],
   "source": [
    "plt.plot(torch.Tensor(test_accuracy).detach().numpy())\n",
    "plt.xlabel('Test iterations')\n",
    "plt.ylabel('Correct classifications (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gJvBYsf7evb"
   },
   "source": [
    "Make the confusion matrix using all of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2mMFo5647mTv"
   },
   "outputs": [],
   "source": [
    "# Create a loader for the entire the test set\n",
    "test_load_all = DataLoader(test_data, batch_size=10000, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_test, y_test in test_load_all:\n",
    "        test_pred_all = model(X_test.to(device))\n",
    "        correct = (test_pred_all.argmax(1) == y_test.to(device))\n",
    "\n",
    "test_pred_all = test_pred_all.cpu().detach().numpy()\n",
    "correct = correct.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "ugH7JdN-9uoB",
    "outputId": "617355af-75cd-4faf-9523-f4bb8746e113"
   },
   "outputs": [],
   "source": [
    "arr = confusion_matrix(test_pred_all.argmax(1), y_test.detach().numpy())\n",
    "\n",
    "df_cm = pd.DataFrame(arr, [class_idx_to_names[i] for i in range(10)], [class_idx_to_names[i] for i in range(10)])\n",
    "plt.figure(figsize = (9,6))\n",
    "sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap='BuGn')\n",
    "plt.xlabel(\"prediction\")\n",
    "plt.ylabel(\"label (ground truth)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seDUNhOu_mII"
   },
   "source": [
    "## Examine the top misses\n",
    "\n",
    "Top misses are defined as the instances that are missclassified but have high confidence in the classified result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wBxxDUmB_lf3"
   },
   "outputs": [],
   "source": [
    "test_class_all  = test_pred_all.argmax(1).astype(int)\n",
    "test_class_true = y_test.detach().numpy()\n",
    "test_probs_all  = np.exp(np.max(test_pred_all, axis = 1))\n",
    "top_misses      = np.argsort(test_probs_all * (1 - correct))[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 829
    },
    "id": "dYK1waIU_4HJ",
    "outputId": "0cd130e0-b510-4239-b1f9-0c3dbe01b68a"
   },
   "outputs": [],
   "source": [
    "img_list = []\n",
    "lab_list = []\n",
    "for i in range(16):\n",
    "    j = top_misses[i]\n",
    "    img_list.append( (X_test[j] * stds.reshape(3,1,1) + means.reshape(3,1,1))  ) # re-normalize\n",
    "    lab_list.append( f'true label: {class_idx_to_names[test_class_true[j]]}\\nfalse label: {class_idx_to_names[test_class_all[j]]}' )\n",
    "img_plotter(img_list, lab_list)\n",
    "plt.subplots_adjust(hspace=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xqeJtmLI_yTj"
   },
   "source": [
    "## Examine the trained filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iSpinZdQLYCd",
    "outputId": "5c4bb782-8f6c-4d12-d691-608fdeae048d"
   },
   "outputs": [],
   "source": [
    "model.features # sequence of modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82xMZU11O-MQ"
   },
   "outputs": [],
   "source": [
    "filters = model.features[0].weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gWG_0DbmO8rb",
    "outputId": "e8d57366-8d50-4b12-b281-6604989079bd"
   },
   "outputs": [],
   "source": [
    "filters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 888
    },
    "id": "6mJOzEJTQRZ-",
    "outputId": "5cebd1e7-1060-4524-b768-52577b2194f8"
   },
   "outputs": [],
   "source": [
    "img_list = []\n",
    "lab_list = []\n",
    "for i in range(6):\n",
    "    img_list.append( filters[i].cpu().detach() )\n",
    "    lab_list.append( f'filter {i}' )\n",
    "img_plotter(img_list, lab_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQ1yEZaHTQwI"
   },
   "source": [
    "## Examine the filtered images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 631
    },
    "id": "H3DQX5b0OyhM",
    "outputId": "adb02f40-ff07-498d-ca4d-95d6f9e02bf9"
   },
   "outputs": [],
   "source": [
    "img_list = [None] * 28\n",
    "lab_list = [None] * 28\n",
    "for i in range(4):\n",
    "    img_list[i] = X_test[i] * stds.reshape(-1,1,1) + means.reshape(-1,1,1)\n",
    "    lab_list[i] = class_idx_to_names[test_class_true[i]]\n",
    "    for j in range(6):\n",
    "        img_list[(j+1)*4+i] = F.conv2d(X_test[i].unsqueeze(0), filters[j].cpu().unsqueeze(0), padding = 1).detach()[0,0,:,:]\n",
    "        lab_list[(j+1)*4+i] = f'filter {j}'\n",
    "img_plotter(img_list, lab_list)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "week6_Alexnet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
